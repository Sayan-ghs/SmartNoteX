# SmartNoteX Backend API

AI-Powered Engineering Notebook Backend built with FastAPI.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- PostgreSQL 12+ (or Supabase PostgreSQL)
- Upstash Redis (for Celery workers) - https://console.upstash.com/
- Supabase account (for file storage) - https://supabase.com/

### Installation

1. **Create virtual environment:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables:**
```bash
cp .env.example .env
# Edit .env with your configuration
```

4. **Create database:**
```bash
# Create PostgreSQL database
createdb smartnotex_db

# Run migrations (when Alembic is set up)
alembic upgrade head

# Initialize pgvector extension and embeddings table
python init_vector_db.py
```

5. **Run the server:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/           # API route handlers
â”‚   â”œâ”€â”€ auth/          # Authentication utilities
â”‚   â”œâ”€â”€ models/        # SQLAlchemy database models
â”‚   â”œâ”€â”€ schemas/       # Pydantic request/response schemas
â”‚   â”œâ”€â”€ services/      # Business logic services
â”‚   â”œâ”€â”€ utils/         # Utility functions
â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â”œâ”€â”€ database.py    # Database connection
â”‚   â””â”€â”€ main.py        # FastAPI application
â”œâ”€â”€ alembic/           # Database migrations
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md
```

## ğŸ” Authentication

The API uses JWT (JSON Web Tokens) for authentication.

### Register a new user:
```bash
POST /api/auth/register
{
  "email": "student@example.com",
  "password": "securepassword",
  "full_name": "John Doe"
}
```

### Login:
```bash
POST /api/auth/login
{
  "email": "student@example.com",
  "password": "securepassword"
}
```

Returns:
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "token_type": "bearer"
}
```

### Use token in requests:
```bash
Authorization: Bearer <access_token>
```

## ğŸ“š API Endpoints

### Notebooks
- `POST /api/notebooks` - Create notebook
- `GET /api/notebooks` - List all notebooks
- `GET /api/notebooks/{id}` - Get notebook
- `PUT /api/notebooks/{id}` - Update notebook
- `DELETE /api/notebooks/{id}` - Delete notebook

### Chapters
- `POST /api/chapters?notebook_id={id}` - Create chapter
- `GET /api/chapters/notebook/{notebook_id}` - List chapters
- `GET /api/chapters/{id}` - Get chapter
- `PUT /api/chapters/{id}` - Update chapter
- `DELETE /api/chapters/{id}` - Delete chapter

### Notes
- `POST /api/notes` - Create note
- `GET /api/notes/chapter/{chapter_id}` - List notes
- `GET /api/notes/{id}` - Get note
- `PUT /api/notes/{id}` - Update note
- `DELETE /api/notes/{id}` - Delete note

### Note Content
- `POST /api/notes/{note_id}/content` - Add content (text/image/PDF)
- `GET /api/notes/{note_id}/content` - List note contents
- `DELETE /api/notes/content/{content_id}` - Delete content

## ğŸ—„ï¸ Database Schema

### Users
- id, email, hashed_password, full_name, is_active, is_verified, timestamps

### Notebooks
- id, title, description, color, owner_id, timestamps

### Chapters
- id, title, description, order_index, notebook_id, timestamps

### Notes
- id, title, chapter_id, is_ai_structured, ai_summary, timestamps

### Note Contents
- id, note_id, content_type, content, file_url, file_name, file_size, order_index, metadata

### Shares
- id, share_type, resource_id, shared_by_user_id, shared_with_user_id, permission, is_public, share_token, expires_at

## ğŸ”§ Development

### Running Tests
```bash
pytest
```

### Database Migrations
```bash
# Create migration
alembic revision --autogenerate -m "description"

# Apply migration
alembic upgrade head

# Rollback
alembic downgrade -1
```

## ğŸ“ Environment Variables

See `.env.example` for all required environment variables.

## ğŸš§ Next Steps

- [ ] Set up Alembic migrations
- [ ] Implement AI note structuring service
- [x] Add vector database integration (pgvector in Supabase)
- [ ] Implement RAG doubt solver
- [ ] Add sharing functionality
- [ ] Set up Celery workers for background tasks

